{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V28",
      "authorship_tag": "ABX9TyP+E8lL9mT7E3ptzVWfXgIA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Syunta-SEKI/Transformer-Learning/blob/main/Train.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K94rX68Y4SLS"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "\n",
        "# Google Drive をマウント\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install janome\n",
        "!pip install torch==2.1.0\n",
        "!pip install torchtext==0.16.0\n",
        "!pip install torchvision==0.16.0"
      ],
      "metadata": {
        "id": "_oR7dVgq53ex"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import torch\n",
        "from torch import nn, Tensor\n",
        "import torch.nn.functional as F\n",
        "from torchtext.vocab import vocab\n",
        "import torchtext.transforms as T\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "import numpy as np\n",
        "import math\n",
        "import janome\n",
        "from janome.tokenizer import Tokenizer\n",
        "import spacy\n",
        "from collections import Counter"
      ],
      "metadata": {
        "id": "oK-M-w3i5nIM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install xlrd"
      ],
      "metadata": {
        "id": "6BV6fxW-N_pG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df = pd.read_excel(\"/content/drive/MyDrive/Transformer/JEC_basic_sentence_v1-3.xls\", header = None)"
      ],
      "metadata": {
        "id": "YtBXIcep8dzF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#日本語用のトークン変換関数を作成\n",
        "j_t = Tokenizer()\n",
        "def j_tokenizer(text):\n",
        "    return [tok for tok in j_t.tokenize(text, wakati=True)]\n",
        "\n",
        "#英語用のトークン変換関数を作成\n",
        "e_t = spacy.load('en_core_web_sm')\n",
        "def e_tokenizer(text):\n",
        "    return [tok.text for tok in e_t.tokenizer(text)]\n",
        "\n",
        "#各文章をトークンに変換\n",
        "texts = df.iloc[:,0].apply(j_tokenizer)\n",
        "targets = df.iloc[:,1].apply(e_tokenizer)\n",
        "\n",
        "print(texts)"
      ],
      "metadata": {
        "id": "jXAxj1soEznJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#日本語のトークン数（単語数）をカウント\n",
        "j_list = []\n",
        "for i in range(len(texts)):\n",
        "  j_list.extend(texts[i])\n",
        "j_counter = Counter()\n",
        "j_counter.update(j_list)\n",
        "j_v = vocab(j_counter, specials=(['<unk>', '<pad>', '<bos>', '<eos>']))   #特殊文字の定義\n",
        "j_v.set_default_index(j_v['<unk>'])\n",
        "\n",
        "#英語のトークン数（単語数）をカウント\n",
        "e_list = []\n",
        "for i in range(len(targets)):\n",
        "  e_list.extend(targets[i])\n",
        "e_counter = Counter()\n",
        "e_counter.update(e_list)\n",
        "e_v = vocab(e_counter, specials=(['<unk>', '<pad>', '<bos>', '<eos>']))   #特殊文字の定義\n",
        "e_v.set_default_index(e_v['<unk>'])\n",
        "\n",
        "enc_vocab_size, dec_vocab_size = len(j_v), len(e_v)\n",
        "print(enc_vocab_size, dec_vocab_size)   #6446 6072"
      ],
      "metadata": {
        "id": "4uzZHv7wE5_u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#各言語ごとに単語数を合わせる必要がある為、1文当たりの単語数を14に指定\n",
        "j_word_count = 14\n",
        "e_word_count = 14\n",
        "\n",
        "j_text_transform = T.Sequential(\n",
        "  T.VocabTransform(j_v),   #トークンに変換\n",
        "  T.Truncate(j_word_count),   #14語以上の文章を14語で切る\n",
        "  T.AddToken(token=j_v['<bos>'], begin=True),   #文頭に'<bos>\n",
        "  T.AddToken(token=j_v['<eos>'], begin=False),   #文末に'<eos>'を追加\n",
        "  T.ToTensor(),   #テンソルに変換\n",
        "  T.PadTransform(j_word_count + 2, j_v['<pad>'])   #14語に満たない文章を'<pad>'で埋めて14語に合わせる\n",
        ")\n",
        "\n",
        "e_text_transform = T.Sequential(\n",
        "  T.VocabTransform(e_v),   #トークンに変換\n",
        "  T.Truncate(e_word_count),   #14語以上の文章を14語で切る\n",
        "  T.AddToken(token=e_v['<bos>'], begin=True),   #文頭に'<bos>\n",
        "  T.AddToken(token=e_v['<eos>'], begin=False),   #文末に'<eos>'を追加\n",
        "  T.ToTensor(),   #テンソルに変換\n",
        "  T.PadTransform(e_word_count + 2, e_v['<pad>'])   #14語に満たない文章を'<pad>'で埋めて14語に合わせる\n",
        ")\n",
        "\n",
        "class Dataset(Dataset):\n",
        "  def __init__(\n",
        "      self,\n",
        "      df,\n",
        "      j_text_transform,\n",
        "      e_text_transform,\n",
        "      ):\n",
        "\n",
        "    self.texts = df.iloc[:,0].apply(j_tokenizer)\n",
        "    self.targets = df.iloc[:,1].apply(e_tokenizer)\n",
        "    self.j_text_transform = j_text_transform\n",
        "    self.e_text_transform = e_text_transform\n",
        "\n",
        "  def max_word(self):\n",
        "    return len(self.j_v), len(self.e_v)\n",
        "\n",
        "  def __getitem__(self, i):\n",
        "    text = self.texts[i]\n",
        "    text = self.j_text_transform([text]).squeeze()\n",
        "\n",
        "    target = self.targets[i]\n",
        "    target = self.e_text_transform([target]).squeeze()\n",
        "\n",
        "    dec_input = target[:-1]\n",
        "    dec_target = target[1:]   #右に1つずらす\n",
        "    data = {\"text\": text, \"dec_input\": dec_input, \"dec_target\": dec_target}\n",
        "    return data\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.texts)\n"
      ],
      "metadata": {
        "id": "QOuvcxAFE51S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 8\n",
        "\n",
        "dataset = Dataset(df, j_text_transform, e_text_transform)\n",
        "data_loader = DataLoader(dataset,\n",
        "                          batch_size=BATCH_SIZE,\n",
        "                          num_workers=4,\n",
        "                          drop_last=True,\n",
        "                          shuffle=True)\n",
        "\n",
        "data = next(iter(data_loader))\n",
        "text, dec_input, target = data[\"text\"], data[\"dec_input\"], data[\"dec_target\"]\n",
        "print(text[0], dec_input[0], target[0], sep=\"\\n\")"
      ],
      "metadata": {
        "id": "Hufa-4fkFDX_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Transformerモデルの実装\n",
        "import math\n",
        "\n",
        "class InputEmbeddings(nn.Module):\n",
        "\n",
        "    def __init__(self, d_model: int, vocab_size: int):\n",
        "        super().__init__()\n",
        "        self.d_model = d_model\n",
        "        self.vocab_size = vocab_size\n",
        "        self.embedding = nn.Embedding(vocab_size, d_model)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.embedding(x) * math.sqrt(self.d_model)\n",
        "\n",
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self, d_model: int, seq_len: int, dropout: float) -> None:\n",
        "        super().__init__()\n",
        "        self.d_model = d_model\n",
        "        self.seq_len = seq_len\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "        pe = torch.zeros(seq_len, d_model)\n",
        "        position = torch.arange(0, seq_len, dtype=torch.float).unsqueeze(1) # unsqueezeにより1番目の次元を追加　(seq_len, 1)型テンソル\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2).float()*(-math.log(10000.0) / d_model))\n",
        "        pe[:, 0::2] = torch.sin(position*div_term)\n",
        "        pe[:, 1::2] = torch.cos(position*div_term)\n",
        "        pe = pe.unsqueeze(0) #形状が(1, seq_len, d_model)になり、バッチ処理が可能に\n",
        "        self.register_buffer(\"pe\", pe)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # xに位置エンコーディングを加える、xにはx.shape[1]までの語数(シーケンス長)が入っているのでそれに合わせて位置エンコーディングを加える\n",
        "        #位置エンコーディングはブロードキャストされてバッチの数だけコピーされてxに加えることができる\n",
        "        x = x + self.pe[:, :x.shape[1], :].detach() #peは勾配を不要にして学習をさせない\n",
        "        return self.dropout(x)\n",
        "\n",
        "class LayerNormalization(nn.Module):\n",
        "\n",
        "    def __init__   (self, eps: float = 10**-6) -> None:\n",
        "        super().__init__()\n",
        "        self.eps = eps\n",
        "        self.alpha = nn.Parameter(torch.ones(1))\n",
        "        self.bias = nn.Parameter(torch.zeros(1))\n",
        "\n",
        "    def forward(self, x):\n",
        "        mean = x.mean(dim=-1, keepdims=True)\n",
        "        std = x.std(dim=-1, keepdims=True)\n",
        "        return self.alpha * (x-mean) / (std + self.eps) + self.bias\n",
        "\n",
        "\n",
        "class FeedForwardBlock(nn.Module):\n",
        "\n",
        "    def __init__(self, d_model: int, d_ff: int, dropout: float) -> None:\n",
        "        super().__init__() #nn.moduleの継承でbackwardなどの基本的機能をこのクラスに継承し、使用可能になる\n",
        "        self.linear_1 = nn.Linear(d_model, d_ff)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.linear_2 = nn.Linear(d_ff, d_model)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.linear_2(self.dropout(torch.relu(self.linear_1(x))))\n",
        "\n",
        "class MultiHeadAttentionBlock(nn.Module):\n",
        "\n",
        "    def __init__(self, d_model: int, h: int, dropout: float) -> None:\n",
        "        super().__init__()\n",
        "        self.d_model = d_model\n",
        "        self.h = h\n",
        "        assert d_model % h ==0\n",
        "\n",
        "        self.d_k = d_model // h\n",
        "        self.w_q = nn.Linear(d_model, d_model)\n",
        "        self.w_k = nn.Linear(d_model, d_model)\n",
        "        self.w_v = nn.Linear(d_model, d_model)\n",
        "\n",
        "        self.w_o = nn.Linear(d_model, d_model)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    @staticmethod\n",
        "    # attentionメソッドはMultiHeadAttentionBlockの他のメソッドを参照しないのでインスタンスメソッドにしなくてよい\n",
        "    # クラス外でもMultiHeadAttentionBlock.attentionとして利用可能\n",
        "    def attention(query, key, value, mask, dropout: nn.Dropout):\n",
        "        d_k = query.shape[-1]\n",
        "        attention_scores = (query @ key.transpose(-2, -1)) / math.sqrt(d_k)\n",
        "        if mask is not None:\n",
        "            attention_scores = attention_scores.masked_fill(mask == 0, float(\"-inf\"))\n",
        "\n",
        "        attention_scores = attention_scores.softmax(dim=-1)\n",
        "        if dropout is not None:\n",
        "            attention_scores = dropout(attention_scores)\n",
        "\n",
        "        return (attention_scores @ value), attention_scores\n",
        "\n",
        "\n",
        "\n",
        "    def forward(self, q, k, v, mask):\n",
        "        query = self.w_q(q) #形状(batch_size, seq_len, d_model)\n",
        "        key = self.w_k(k) #形状(batch_size, seq_len, d_model)\n",
        "        value = self.w_v(v)#形状(batch_size, seq_len, d_model)\n",
        "\n",
        "        query = query.view(query.shape[0], query.shape[1], self.h, self.d_k).transpose(1, 2) #形状(batch_size, h, seq_len, d_k)\n",
        "        key = key.view(key.shape[0], key.shape[1], self.h, self.d_k).transpose(1, 2)\n",
        "        value = value.view(value.shape[0], value.shape[1], self.h, self.d_k).transpose(1, 2)\n",
        "\n",
        "        x, self.attention_scores = MultiHeadAttentionBlock.attention(query, key, value, mask, self.dropout)\n",
        "\n",
        "        x = x.transpose(1, 2).contiguous().view(x.shape[0], -1, self.h*self.d_k) #形状(batch_size, seq_len, d_model)\n",
        "        return self.w_o(x) #形状(batch_size, seq_len, d_model)\n",
        "\n",
        "\n",
        "class ResidualConnection(nn.Module):\n",
        "\n",
        "    def __init__(self, dropout: float) -> None:\n",
        "        super().__init__()\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.norm = LayerNormalization()\n",
        "\n",
        "    def forward(self, x, sublayer):\n",
        "        return x + self.dropout(sublayer(self.norm(x)))\n",
        "\n",
        "class EncoderBlock(nn.Module):\n",
        "\n",
        "    def __init__(self, self_attention_block: MultiHeadAttentionBlock, feed_forward_block: FeedForwardBlock, dropout: float) -> None:\n",
        "        super().__init__()\n",
        "        self.self_attention_block = self_attention_block\n",
        "        self.feed_forward_block = feed_forward_block\n",
        "        self.residual_connections = nn.ModuleList([ResidualConnection(dropout) for _ in range(2)])\n",
        "\n",
        "    def forward(self, x, src_mask):\n",
        "        x = self.residual_connections[0](x, lambda x: self.self_attention_block(x, x, x, src_mask))\n",
        "        x = self.residual_connections[1](x, self.feed_forward_block)\n",
        "        return x\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "\n",
        "    def __init__(self, layers: nn.ModuleList) -> None:\n",
        "        super().__init__()\n",
        "        self.layers = layers\n",
        "        self.norm = LayerNormalization()\n",
        "\n",
        "    #self.layersはEncoderBlockオブジェクトを格納\n",
        "    def forward(self, x, mask):\n",
        "        for layer in self.layers:\n",
        "            x = layer(x, mask)\n",
        "        return self.norm(x)\n",
        "\n",
        "class DecoderBlock(nn.Module):\n",
        "\n",
        "    def __init__(self, self_attention_block: MultiHeadAttentionBlock, cross_attention_block: MultiHeadAttentionBlock, feed_forward_block: FeedForwardBlock, dropout: float):\n",
        "        super().__init__()\n",
        "        self.self_attention_block = self_attention_block\n",
        "        self.cross_attention_block = cross_attention_block\n",
        "        self.feed_forward_block = feed_forward_block\n",
        "        self.residual_connections = nn.ModuleList([ResidualConnection(dropout) for _ in range(3)])\n",
        "\n",
        "    def forward(self, x, encoder_output, src_mask, tgt_mask):\n",
        "        x = self.residual_connections[0](x, lambda x: self.self_attention_block(x, x, x, tgt_mask))\n",
        "        x = self.residual_connections[1](x, lambda x:self.cross_attention_block(x, encoder_output, encoder_output, src_mask))\n",
        "        x = self.residual_connections[2](x, self.feed_forward_block)\n",
        "        return x\n",
        "\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "\n",
        "    def __init__(self, layers: nn.ModuleList) -> None:\n",
        "        super().__init__()\n",
        "        self.layers = layers\n",
        "        self.norm = LayerNormalization()\n",
        "\n",
        "    def forward(self, x, encoder_output, src_mask, tgt_mask):\n",
        "        for layer in self.layers:\n",
        "            x = layer(x, encoder_output, src_mask, tgt_mask)\n",
        "        return self.norm(x)\n",
        "\n",
        "\n",
        "\n",
        "class ProjectionLayer(nn.Module):\n",
        "\n",
        "    def __init__(self, d_model: int, vocab_size: int) -> None:\n",
        "        super().__init__()\n",
        "        self.proj = nn.Linear(d_model, vocab_size)\n",
        "        #self.projの出力は(batch_size, seq_len, vocab_size)で、各バッチの各トークンの次のトークンを予測する\n",
        "\n",
        "    def forward(self, x):\n",
        "        return torch.log_softmax(self.proj(x), dim = -1)\n",
        "\n",
        "class Transformer(nn.Module):\n",
        "\n",
        "    def __init__(self, encoder: Encoder, decoder: Decoder, src_embed: InputEmbeddings, tgt_embed: InputEmbeddings, src_pos: PositionalEncoding, tgt_pos: PositionalEncoding, projection_layer: ProjectionLayer) -> None:\n",
        "        super().__init__()\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.src_embed = src_embed\n",
        "        self.tgt_embed = tgt_embed\n",
        "        self.src_pos = src_pos\n",
        "        self.tgt_pos = tgt_pos\n",
        "        self.projection_layer = projection_layer\n",
        "\n",
        "    def encode(self, src, src_mask):\n",
        "        src = self.src_embed(src)\n",
        "        src = self.src_pos(src)\n",
        "        return self.encoder(src, src_mask)\n",
        "\n",
        "    def decode(self, tgt, encoder_output, src_mask, tgt_mask):\n",
        "        tgt = self.tgt_embed(tgt)\n",
        "        tgt = self.tgt_pos(tgt)\n",
        "        return self.decoder(tgt, encoder_output, src_mask, tgt_mask)\n",
        "\n",
        "    def project(self, x):\n",
        "        return self.projection_layer(x)\n",
        "\n",
        "\n",
        "def build_transformer(src_vocab_size: int, tgt_vocab_size: int, src_seq_len: int, tgt_seq_len: int, d_model: int = 512, N: int = 6, h: int = 8, dropout: float = 0.1, d_ff: int = 2048) -> Transformer:\n",
        "    src_embed = InputEmbeddings(d_model, src_vocab_size)\n",
        "    tgt_embed = InputEmbeddings(d_model, tgt_vocab_size)\n",
        "    src_pos = PositionalEncoding(d_model, src_seq_len, dropout)\n",
        "    tgt_pos = PositionalEncoding(d_model, tgt_seq_len, dropout)\n",
        "\n",
        "    encoder_blocks = []\n",
        "    for _ in range(N):\n",
        "        encoder_self_attention_block = MultiHeadAttentionBlock(d_model, h, dropout)\n",
        "        feed_forward_block = FeedForwardBlock(d_model, d_ff, dropout)\n",
        "        encoder_block = EncoderBlock(encoder_self_attention_block, feed_forward_block, dropout)\n",
        "        encoder_blocks.append(encoder_block)\n",
        "\n",
        "    decoder_blocks = []\n",
        "    for _ in range(N):\n",
        "        decoder_self_attention_block = MultiHeadAttentionBlock(d_model, h, dropout)\n",
        "        decoder_cross_attention_block = MultiHeadAttentionBlock(d_model, h, dropout)\n",
        "        feed_forward_block = FeedForwardBlock(d_model, d_ff, dropout)\n",
        "        decoder_block = DecoderBlock(decoder_self_attention_block, decoder_cross_attention_block, feed_forward_block, dropout)\n",
        "        decoder_blocks.append(decoder_block)\n",
        "\n",
        "    encoder = Encoder(nn.ModuleList(encoder_blocks))\n",
        "    decoder = Decoder(nn.ModuleList(decoder_blocks))\n",
        "    projection_layer = ProjectionLayer(d_model, tgt_vocab_size)\n",
        "    transformer = Transformer(encoder, decoder, src_embed, tgt_embed, src_pos, tgt_pos, projection_layer)\n",
        "\n",
        "    for p in transformer.parameters():\n",
        "        if p.dim() > 1:\n",
        "            nn.init.xavier_uniform(p)\n",
        "\n",
        "\n",
        "    return transformer\n",
        "\n"
      ],
      "metadata": {
        "id": "_sotxWrHFXM9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def make_pad_mask(tensor, pad_idx):\n",
        "    \"\"\"\n",
        "    tensor: (batch_size, seq_len)\n",
        "    pad_idx: <pad> に対応するインデックス\n",
        "    return: (batch_size, 1, 1, seq_len)  [TransformerのAttnが期待する形状]\n",
        "    \"\"\"\n",
        "    # pad 部分が 0 のマスクを作りたい場合は以下のように == pad_idx\n",
        "    mask = (tensor != pad_idx).unsqueeze(1).unsqueeze(2)\n",
        "    return mask  # True=Attend, False=Ignore\n",
        "\n",
        "def make_subsequent_mask(tensor):\n",
        "    \"\"\"\n",
        "    tensor: (batch_size, seq_len)\n",
        "    サブシーケンスマスク (未来の単語を参照しないため) を作成\n",
        "    \"\"\"\n",
        "    batch_size, seq_len = tensor.size()\n",
        "    # (seq_len, seq_len) のアッパートライアングル部分が Trueになるマスク\n",
        "    subsequent_mask = torch.triu(torch.ones(seq_len, seq_len), diagonal=1).bool()\n",
        "    # バッチ次元を追加\n",
        "    subsequent_mask = subsequent_mask.unsqueeze(0).repeat(batch_size, 1, 1)\n",
        "    # 最終的には (batch_size, 1, seq_len, seq_len) などに reshape\n",
        "    # MultiHeadAttentionBlock の実装に合わせて必要に応じて reshape\n",
        "    return subsequent_mask.unsqueeze(1)  # (B, 1, seq_len, seq_len)\n"
      ],
      "metadata": {
        "id": "PFaOhjgoKLbr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# (1) モデルのビルド\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# 上で得た単語数\n",
        "enc_vocab_size = len(j_v)\n",
        "dec_vocab_size = len(e_v)\n",
        "\n",
        "# トークン列の長さ + <bos>, <eos> で固定長(=16)を想定しているなら\n",
        "src_seq_len = j_word_count + 2  # 14 + <bos>,<eos> の分\n",
        "tgt_seq_len = e_word_count + 2  # 14 + <bos>,<eos> の分\n",
        "\n",
        "model = build_transformer(\n",
        "    src_vocab_size=enc_vocab_size,\n",
        "    tgt_vocab_size=dec_vocab_size,\n",
        "    src_seq_len=src_seq_len,\n",
        "    tgt_seq_len=tgt_seq_len,\n",
        "    d_model=128,     # 小さめに設定（メモリに応じて調整）\n",
        "    N=2,            # 層数（デモ用に2）\n",
        "    h=4,            # ヘッド数（同上）\n",
        "    dropout=0.1,\n",
        "    d_ff=256        # FF層の次元\n",
        ").to(device)\n",
        "\n",
        "# (2) ロス関数とオプティマイザ\n",
        "# ProjectionLayer が log_softmax を返すので NLLLoss を使用\n",
        "criterion = nn.NLLLoss(ignore_index=e_v['<pad>'])\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
        "\n",
        "# (3) 学習ループ\n",
        "num_epochs = 10\n",
        "model.train()\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    total_loss = 0.0\n",
        "\n",
        "    for batch in data_loader:\n",
        "        # batch は {\"text\": text, \"dec_input\": dec_input, \"dec_target\": dec_target}\n",
        "        src = batch[\"text\"].to(device)       # (B, src_seq_len)\n",
        "        dec_in = batch[\"dec_input\"].to(device)  # (B, tgt_seq_len)\n",
        "        dec_tgt = batch[\"dec_target\"].to(device) # (B, tgt_seq_len)\n",
        "\n",
        "        # --- マスク作成 (PADトークン無視用) ---\n",
        "        src_mask = make_pad_mask(src, pad_idx=j_v['<pad>'])\n",
        "        tgt_mask = make_pad_mask(dec_in, pad_idx=e_v['<pad>'])\n",
        "\n",
        "        # --- (必要に応じて) サブシーケンスマスクを tgt_mask に組み合わせ ---\n",
        "        # subsequent = make_subsequent_mask(dec_in)\n",
        "        # tgt_mask = tgt_mask & subsequent  # 未来を見ない & PADを見ない\n",
        "\n",
        "        # 順伝播\n",
        "        encoder_output = model.encode(src, src_mask)\n",
        "        decoder_output = model.decode(dec_in, encoder_output, src_mask, tgt_mask)\n",
        "        logits = model.project(decoder_output)  # (B, tgt_seq_len, dec_vocab_size)\n",
        "\n",
        "        # ロス計算\n",
        "        # nn.NLLLoss の入力は (N, C, ...) なので次元を入れ替える\n",
        "        loss = criterion(logits.permute(0, 2, 1), dec_tgt)\n",
        "\n",
        "        # 逆伝播 & パラメータ更新\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    avg_loss = total_loss / len(data_loader)\n",
        "    print(f\"[Epoch {epoch+1}] loss: {avg_loss:.4f}\")\n",
        "\n",
        "    # --- (ここで Google Drive にモデルの重みを保存) ---\n",
        "    save_path = f\"/content/drive/MyDrive/Transformer/transformer_epoch_{epoch+1}.pth\"\n",
        "    torch.save(model.state_dict(), save_path)\n",
        "    print(f\"Model weights saved to {save_path}\")\n"
      ],
      "metadata": {
        "id": "5xiCQn-EKTkP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = build_transformer(\n",
        "    src_vocab_size=enc_vocab_size,\n",
        "    tgt_vocab_size=dec_vocab_size,\n",
        "    src_seq_len=src_seq_len,\n",
        "    tgt_seq_len=tgt_seq_len,\n",
        "    d_model=128,\n",
        "    N=2,\n",
        "    h=4,\n",
        "    dropout=0.1,\n",
        "    d_ff=256\n",
        ").to(device)\n",
        "\n",
        "model.load_state_dict(torch.load(\"/content/drive/MyDrive/Transformer/transformer_epoch_10.pth\"))\n",
        "print(\"Model weights loaded successfully!\")"
      ],
      "metadata": {
        "id": "4NTzXMk2Q7C7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}